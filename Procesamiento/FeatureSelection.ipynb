{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://http2.mlstatic.com/D_NQ_NP_2X_960089-MLM26807621582_022018-F.webp\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2023\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Selección de Variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selección de variables es un proceso donde automáticamente se seleccionan aquellos atributos en nuestros datos que contribuyen más a la variable a predecir. \n",
    "\n",
    "Las variables irrelevantes o parcialmente relevantes pueden afectar negativamente el rendimiento del modelo.\n",
    "\n",
    "Beneficios:\n",
    "- Reducir sobreajuste: menos datos irrelevantes significan menos oportunidades de tomar decisiones basadas en ruido = mejor performance. \n",
    "- Modelo más fácil de entender\n",
    "- Reduce el tiempo de entrenamiento: menos datos significa que el modelo se entrena más rápido\n",
    "\n",
    "\n",
    "**Tipos de algoritmos de selección de variables**\n",
    "\n",
    "- **Supervisado**: se basa la selección en la variable objetivo.\n",
    "\n",
    "    - Métodos de envoltura: se considera como un problema de búsqueda la selección de un conjunto de variables donde diferentes combinaciones se preparan, evalúan y comparan con otras combinaciones. Se utiliza un modelo predictivo para evaluar una combinación de características y asignar un score basado en la precisión del modelo. \n",
    "        - Ejemplo: RFE\n",
    "\n",
    "    - Métodos de filtrado: estos métodos aplican una medida estadística para asignar una puntuación a cada característica. Las características se clasifican según la puntuación y se seleccionan para conservarlas o eliminarlas del conjunto de datos. Los métodos suelen ser univariados y consideran la característica de forma independiente o con respecto a la variable dependiente.\n",
    "        - Ejemplo: prueba de chi cuadrada, L-Anova, método de correlación, criterio de la varianza\n",
    "\n",
    "    - Métodos embebidos: mientras se va creando el modelo el método aprende qué características contribuyen mejor a la precisión. El método más común es el de regularización. \n",
    "        - Ejemplo: LASSO, Elastic Net, Ridge, Trees\n",
    "\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/11/Overview-of-Feature-Selection-Techniques3.png\" width=\"550\" height=\"480\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mencionando algunas técnicas más comunes:**\n",
    "\n",
    "- Porcentaje de valores nulos\n",
    "- Cantidad de variación\n",
    "- Correlación por parejas\n",
    "- Mulicolinealidad\n",
    "- PCA\n",
    "- Correlación con la variable a predecir (target)\n",
    "- Forward Selection\n",
    "- Backward Selection\n",
    "- Stepwise Selection\n",
    "- LASSO\n",
    "- Selección basada en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de variables\n",
    "\n",
    "La decisión de qué medida estadística utilizar en muchos casos depende del tipo de las variables. \n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2020/06/Overview-of-Data-Variable-Types2.png\" width=\"550\" height=\"480\" align=\"center\"/>\n",
    "\n",
    "Entre más se sepa del tipo de variable es más fácil elegir qué medida estadística se va a utilizar, sobre todo para los métodos de filtrado \n",
    "\n",
    "**¿Cómo elegir las mejores variables?**\n",
    "No es una respuesta fácil, hay que tratar de varias formas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos: Glass Identification Data Set\n",
    "Los datos se pueden encontrar en:\n",
    "https://archive.ics.uci.edu/ml/datasets/glass+identification\n",
    "\n",
    "Se busca identificar qué tipo de vidrio es una muestra. \n",
    "\n",
    "\n",
    "- 1. Id number: 1 a 214\n",
    "- 2. RI: Indice Refractivo(medida para saber cuánto se reduce la velocidad de la luz al atravesarlo)\n",
    "- 3. Na: Sodio (unidad de medida: porcentaje en peso en el óxido correspondiente, como son los atributos 4-10)\n",
    "- 4. Mg: Magenesio\n",
    "- 5. Al: Aluminio\n",
    "- 6. Si: Silicon\n",
    "- 7. K: Potasio\n",
    "- 8. Ca: Calcio\n",
    "- 9. Ba: Bario\n",
    "- 10. Fe: Hierro\n",
    "- 11. Tipo de Vidrio: \n",
    "-- 1 ventanas de edificios procesadas por flotación \n",
    "-- 2 ventanas de edificios no procesadas por flotación \n",
    "-- 3 ventanas de vehículos procesadas por flotación\n",
    "-- 4 ventanas de vehículos no procesadas por flotación \n",
    "-- 5 contenedores\n",
    "-- 6 vajilla\n",
    "-- 7 faros\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://archive.ics.uci.edu/ml/assets/logo.gif\" width=\"350px\" height=\"180px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos del vidrio (variable a predecir categórica)\n",
    "data = pd.read_csv('./data/glass.data',header=None)\n",
    "names = ['ID','Indice_Refraccion','Na','Mg','Al','Si','K', 'Ca','Ba','Fe','Tipo_Vidrio']\n",
    "data.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Tipo_Vidrio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Indice_Refraccion     Na    Mg    Al     Si     K    Ca   Ba   Fe  \\\n",
       "0   1            1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   \n",
       "1   2            1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   \n",
       "2   3            1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   \n",
       "3   4            1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   \n",
       "4   5            1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   \n",
       "\n",
       "   Tipo_Vidrio  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de eliminación sólo variables predictoras (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar variable con % de datos nulos\n",
    "\n",
    "Cuando hay muchos datos nulos, es difícil para el algoritmo aprender de esos datos (ya que no hay nada)\n",
    "\n",
    "Hay 2 opciones:\n",
    "1. Quitar variables que tienen un % alto de datos nulos\n",
    "\n",
    "   (\\# de datos con valores nulos/ \\# total de datos) \n",
    "   \n",
    "   \n",
    "2. Crear indicadores binarios que explícitamente digan existente / valor nulo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la Varianza\n",
    "\n",
    "Este algoritmo se enfoca sólo en las variables independientes (X) y NO en la variables a predecir (y), por eso se le puede usar para aprendizaje no supervisado. \n",
    "\n",
    "Si la variable tiene casi los mismos valores, entonces el modelo no va a aprender nada de esa variable. \n",
    "\n",
    "\n",
    "$$\\begin{matrix} 5 & 19 & 6.8 & 100 & 22\\\\ 5 & 25 & 7.2 & 150 & 23\\\\ 5 & 15 & 4.5 & 90 & 19\\\\ 4 & 30 & 8.9 & 125 & 25\\\\ 5 & 18 & 9.5 & 75 & 15\\\\\\end{matrix}$$\n",
    "\n",
    "Se recomienda estandarizar todas las variables para tomar encuenta las diferentes escalas.\n",
    "\n",
    "Por lo general se remueven las variables con varianza muy cercana a cero. \n",
    "\n",
    "Métricas de evaluación:\n",
    "- Con un umbral de varianza. Se remueven las variables cuya varianza no alcanza el límite propuesto. \n",
    "- La proporción entre valores únicos y el total de muestras es bajo $\\frac{Valores_{unicos}}{muestras_{totales}}<0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Indice_Refraccion     Na    Mg    Al     Si     K    Ca    Ba   Fe\n",
       "0              1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
       "1              1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
       "2              1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
       "3              1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
       "4              1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
       "..                 ...    ...   ...   ...    ...   ...   ...   ...  ...\n",
       "209            1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
       "210            1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
       "211            1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
       "212            1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
       "213            1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
       "\n",
       "[214 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tomamos sólo variables de interés (variables predictoras X)\n",
    "data.iloc[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.437594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.308550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.801782</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>0.223048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.220808</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.790646</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.062802</td>\n",
       "      <td>0.218401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285777</td>\n",
       "      <td>0.372932</td>\n",
       "      <td>0.821826</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.259294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275241</td>\n",
       "      <td>0.381955</td>\n",
       "      <td>0.806236</td>\n",
       "      <td>0.295950</td>\n",
       "      <td>0.583929</td>\n",
       "      <td>0.088567</td>\n",
       "      <td>0.245353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indice_Refraccion        Na        Mg        Al        Si         K  \\\n",
       "0           0.432836  0.437594  1.000000  0.252336  0.351786  0.009662   \n",
       "1           0.283582  0.475188  0.801782  0.333333  0.521429  0.077295   \n",
       "2           0.220808  0.421053  0.790646  0.389408  0.567857  0.062802   \n",
       "3           0.285777  0.372932  0.821826  0.311526  0.500000  0.091787   \n",
       "4           0.275241  0.381955  0.806236  0.295950  0.583929  0.088567   \n",
       "\n",
       "         Ca   Ba   Fe  \n",
       "0  0.308550  0.0  0.0  \n",
       "1  0.223048  0.0  0.0  \n",
       "2  0.218401  0.0  0.0  \n",
       "3  0.259294  0.0  0.0  \n",
       "4  0.245353  0.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estandarizar los datos\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = data.columns[1:10]\n",
    "d = scaler.fit_transform(data.iloc[:,1:10])\n",
    "scaled_df = pd.DataFrame(d, columns=names)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Umbral de la varianza (threshold) A Mano\n",
    "\n",
    "varianzas = pd.DataFrame(scaled_df.var().sort_values(),columns=[\"Varianza\"])\n",
    "\n",
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i,round(y[i],3),round(y[i],3))\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.bar(np.arange(len(varianzas)),varianzas.Varianza)\n",
    "plt.ylabel('Varianza')\n",
    "plt.xticks(np.arange(len(varianzas)),varianzas.index,rotation=90)\n",
    "addlabels(np.arange(len(varianzas)), varianzas.Varianza)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A mano cómo selecciono las variables una vez calculada la varianza?\n",
    "\n",
    "Selecciono un \"threshold\" o valor, como límite para tomar mi decisión. \n",
    "Por ejemplo:\n",
    "\n",
    "Yo quiero sólo quedarme con los datos que varíen más de 0.02\n",
    "\n",
    "Threhold = 0.02\n",
    "\n",
    "Por lo tanto, me quedo sólo con las variables de: Al, Ba, Fe y Mg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.25233645, 0.        , 0.        ],\n",
       "       [0.80178174, 0.33333333, 0.        , 0.        ],\n",
       "       [0.79064588, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.82182628, 0.31152648, 0.        , 0.        ],\n",
       "       [0.80623608, 0.29595016, 0.        , 0.        ],\n",
       "       [0.80400891, 0.41433022, 0.        , 0.50980392],\n",
       "       [0.80178174, 0.26479751, 0.        , 0.        ],\n",
       "       [0.80400891, 0.23676012, 0.        , 0.        ],\n",
       "       [0.79732739, 0.3364486 , 0.        , 0.        ],\n",
       "       [0.80178174, 0.33333333, 0.        , 0.21568627],\n",
       "       [0.77060134, 0.39563863, 0.        , 0.47058824],\n",
       "       [0.81514477, 0.30529595, 0.        , 0.        ],\n",
       "       [0.76391982, 0.34579439, 0.        , 0.47058824],\n",
       "       [0.79287305, 0.30529595, 0.        , 0.33333333],\n",
       "       [0.79955457, 0.31775701, 0.        , 0.        ],\n",
       "       [0.78841871, 0.29283489, 0.        , 0.        ],\n",
       "       [0.81737194, 0.27102804, 0.        , 0.        ],\n",
       "       [0.85746102, 0.18691589, 0.        , 0.        ],\n",
       "       [0.83073497, 0.27725857, 0.        , 0.        ],\n",
       "       [0.78841871, 0.43613707, 0.        , 0.1372549 ],\n",
       "       [0.79064588, 0.37383178, 0.        , 0.37254902],\n",
       "       [0.83518931, 0.        , 0.        , 0.        ],\n",
       "       [0.80623608, 0.31152648, 0.        , 0.        ],\n",
       "       [0.79510022, 0.33021807, 0.        , 0.        ],\n",
       "       [0.77951002, 0.26791277, 0.        , 0.        ],\n",
       "       [0.78841871, 0.28660436, 0.        , 0.        ],\n",
       "       [0.77505568, 0.34890966, 0.        , 0.        ],\n",
       "       [0.77505568, 0.32398754, 0.        , 0.        ],\n",
       "       [0.78396437, 0.35514019, 0.        , 0.        ],\n",
       "       [0.77728285, 0.30841121, 0.        , 0.        ],\n",
       "       [0.79287305, 0.31464174, 0.        , 0.2745098 ],\n",
       "       [0.77951002, 0.26479751, 0.        , 0.        ],\n",
       "       [0.77505568, 0.29283489, 0.02857143, 0.43137255],\n",
       "       [0.77282851, 0.33956386, 0.        , 0.11764706],\n",
       "       [0.78841871, 0.3271028 , 0.        , 0.        ],\n",
       "       [0.76837416, 0.28660436, 0.        , 0.        ],\n",
       "       [0.78619154, 0.32087227, 0.03492063, 0.        ],\n",
       "       [0.77505568, 0.33021807, 0.        , 0.        ],\n",
       "       [0.85077951, 0.05607477, 0.        , 0.        ],\n",
       "       [0.85077951, 0.05607477, 0.        , 0.        ],\n",
       "       [0.77951002, 0.25856698, 0.        , 0.        ],\n",
       "       [0.76169265, 0.2834891 , 0.        , 0.        ],\n",
       "       [0.75501114, 0.32398754, 0.        , 0.        ],\n",
       "       [0.85523385, 0.13395639, 0.        , 0.        ],\n",
       "       [0.76391982, 0.28037383, 0.        , 0.58823529],\n",
       "       [0.77505568, 0.33021807, 0.        , 0.        ],\n",
       "       [0.75055679, 0.27725857, 0.        , 0.31372549],\n",
       "       [0.82405345, 0.13084112, 0.        , 0.19607843],\n",
       "       [0.83964365, 0.15576324, 0.        , 0.        ],\n",
       "       [0.74610245, 0.29283489, 0.        , 0.        ],\n",
       "       [0.8285078 , 0.06853583, 0.        , 0.31372549],\n",
       "       [0.74164811, 0.30841121, 0.        , 0.21568627],\n",
       "       [0.63919822, 0.28037383, 0.        , 0.        ],\n",
       "       [0.6325167 , 0.30841121, 0.        , 0.        ],\n",
       "       [0.62583519, 0.31152648, 0.        , 0.17647059],\n",
       "       [0.60356347, 0.31152648, 0.        , 0.47058824],\n",
       "       [0.77282851, 0.25856698, 0.        , 0.60784314],\n",
       "       [0.77505568, 0.31152648, 0.        , 0.        ],\n",
       "       [0.83296214, 0.2741433 , 0.        , 0.        ],\n",
       "       [0.81514477, 0.28037383, 0.        , 0.21568627],\n",
       "       [0.80623608, 0.25545171, 0.        , 0.        ],\n",
       "       [0.79732739, 0.32087227, 0.21904762, 0.        ],\n",
       "       [0.8596882 , 0.18380062, 0.        , 0.21568627],\n",
       "       [0.84855234, 0.15264798, 0.        , 0.        ],\n",
       "       [0.83296214, 0.19003115, 0.        , 0.1372549 ],\n",
       "       [0.79955457, 0.25856698, 0.        , 0.        ],\n",
       "       [0.81291759, 0.18068536, 0.        , 0.33333333],\n",
       "       [0.81291759, 0.18068536, 0.        , 0.33333333],\n",
       "       [0.79732739, 0.19003115, 0.        , 0.31372549],\n",
       "       [0.79732739, 0.16510903, 0.        , 0.05882353],\n",
       "       [0.81737194, 0.4517134 , 0.        , 0.23529412],\n",
       "       [0.86191537, 0.30529595, 0.        , 0.62745098],\n",
       "       [0.79955457, 0.38317757, 0.        , 0.        ],\n",
       "       [0.79510022, 0.39875389, 0.        , 0.        ],\n",
       "       [0.79287305, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.79732739, 0.38006231, 0.        , 0.        ],\n",
       "       [0.80400891, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.79732739, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.78396437, 0.29906542, 0.        , 0.2745098 ],\n",
       "       [0.78396437, 0.50155763, 0.        , 0.        ],\n",
       "       [0.78396437, 0.57009346, 0.        , 0.        ],\n",
       "       [0.76837416, 0.35514019, 0.        , 0.        ],\n",
       "       [0.79064588, 0.29906542, 0.        , 0.        ],\n",
       "       [0.78396437, 0.39252336, 0.        , 0.17647059],\n",
       "       [0.68819599, 0.5576324 , 0.        , 0.        ],\n",
       "       [0.79732739, 0.37383178, 0.        , 0.        ],\n",
       "       [0.77728285, 0.36760125, 0.        , 0.        ],\n",
       "       [0.77728285, 0.38317757, 0.        , 0.19607843],\n",
       "       [0.77951002, 0.37071651, 0.        , 0.        ],\n",
       "       [0.77505568, 0.49221184, 0.        , 0.17647059],\n",
       "       [0.83296214, 0.25545171, 0.        , 0.43137255],\n",
       "       [0.76614699, 0.36137072, 0.        , 0.        ],\n",
       "       [0.75946548, 0.40186916, 0.        , 0.37254902],\n",
       "       [0.74387528, 0.36760125, 0.        , 0.        ],\n",
       "       [0.74164811, 0.37383178, 0.        , 0.        ],\n",
       "       [0.76391982, 0.35514019, 0.        , 0.        ],\n",
       "       [0.80623608, 0.23987539, 0.        , 0.29411765],\n",
       "       [0.72383073, 0.27102804, 0.        , 0.47058824],\n",
       "       [0.64142539, 0.4423676 , 0.        , 0.        ],\n",
       "       [0.65924276, 0.35514019, 0.04444444, 0.        ],\n",
       "       [0.63474388, 0.35825545, 0.03492063, 0.43137255],\n",
       "       [0.60579065, 0.41744548, 0.        , 0.        ],\n",
       "       [0.61469933, 0.1682243 , 0.        , 0.39215686],\n",
       "       [0.70155902, 0.1152648 , 0.        , 0.        ],\n",
       "       [0.64587973, 0.2741433 , 0.        , 0.        ],\n",
       "       [0.        , 0.4953271 , 0.        , 0.66666667],\n",
       "       [0.        , 0.56386293, 1.        , 0.54901961],\n",
       "       [0.        , 0.2211838 , 0.        , 0.47058824],\n",
       "       [0.        , 0.2211838 , 0.        , 0.15686275],\n",
       "       [0.        , 0.08411215, 0.        , 0.        ],\n",
       "       [0.        , 0.14953271, 0.        , 0.        ],\n",
       "       [0.        , 0.14330218, 0.        , 0.        ],\n",
       "       [0.        , 0.11838006, 0.        , 0.        ],\n",
       "       [0.85300668, 0.30218069, 0.        , 0.2745098 ],\n",
       "       [0.88418708, 0.28037383, 0.        , 0.        ],\n",
       "       [0.86636971, 0.32398754, 0.        , 0.        ],\n",
       "       [0.86859688, 0.34890966, 0.        , 0.19607843],\n",
       "       [0.81959911, 0.47352025, 0.        , 0.        ],\n",
       "       [0.81069042, 0.38629283, 0.        , 0.56862745],\n",
       "       [0.79510022, 0.36760125, 0.        , 0.        ],\n",
       "       [0.83741648, 0.32087227, 0.        , 0.        ],\n",
       "       [0.78841871, 0.41433022, 0.        , 0.41176471],\n",
       "       [0.78841871, 0.37071651, 0.        , 0.        ],\n",
       "       [0.77505568, 0.4423676 , 0.        , 0.        ],\n",
       "       [0.81959911, 0.26791277, 0.        , 0.        ],\n",
       "       [0.81514477, 0.39563863, 0.        , 0.23529412],\n",
       "       [0.80400891, 0.30218069, 0.        , 0.        ],\n",
       "       [0.5077951 , 0.35514019, 0.        , 0.33333333],\n",
       "       [0.46547884, 0.42990654, 0.08571429, 0.33333333],\n",
       "       [0.30066815, 0.41744548, 0.        , 0.35294118],\n",
       "       [0.22494432, 0.33333333, 0.        , 0.        ],\n",
       "       [0.        , 0.33333333, 0.        , 0.19607843],\n",
       "       [0.88641425, 0.27725857, 0.        , 0.        ],\n",
       "       [0.8752784 , 0.3894081 , 0.        , 0.29411765],\n",
       "       [0.85746102, 0.29906542, 0.        , 0.        ],\n",
       "       [0.86859688, 0.31464174, 0.        , 0.54901961],\n",
       "       [0.84632517, 0.24610592, 0.        , 0.23529412],\n",
       "       [0.80623608, 0.39875389, 0.        , 0.        ],\n",
       "       [0.78396437, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.79287305, 0.42056075, 0.        , 0.        ],\n",
       "       [0.78841871, 0.41121495, 0.        , 0.        ],\n",
       "       [0.80846325, 0.24299065, 0.02857143, 0.33333333],\n",
       "       [0.78173719, 0.35825545, 0.01904762, 0.49019608],\n",
       "       [0.77282851, 0.46728972, 0.        , 0.        ],\n",
       "       [0.70824053, 0.29283489, 0.        , 0.47058824],\n",
       "       [0.81737194, 0.29595016, 0.        , 0.68627451],\n",
       "       [0.81514477, 0.25545171, 0.        , 0.        ],\n",
       "       [0.78619154, 0.3271028 , 0.        , 0.        ],\n",
       "       [0.79510022, 0.33956386, 0.        , 0.19607843],\n",
       "       [0.78396437, 0.33021807, 0.        , 0.        ],\n",
       "       [0.76837416, 0.45794393, 0.        , 0.33333333],\n",
       "       [0.86859688, 0.1682243 , 0.        , 0.        ],\n",
       "       [0.81291759, 0.11214953, 0.        , 0.        ],\n",
       "       [0.75723831, 0.28971963, 0.        , 0.        ],\n",
       "       [0.79732739, 0.31775701, 0.        , 0.        ],\n",
       "       [0.75723831, 0.30218069, 0.        , 0.        ],\n",
       "       [0.75501114, 0.30841121, 0.        , 0.        ],\n",
       "       [0.83741648, 0.09034268, 0.        , 0.        ],\n",
       "       [0.75946548, 0.38317757, 0.        , 0.        ],\n",
       "       [0.74832962, 0.41744548, 0.        , 0.17647059],\n",
       "       [0.74387528, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.78841871, 0.14330218, 0.04761905, 0.47058824],\n",
       "       [0.84187082, 0.19314642, 0.        , 0.7254902 ],\n",
       "       [0.59688196, 1.        , 0.6984127 , 0.        ],\n",
       "       [0.41202673, 0.48909657, 0.        , 0.        ],\n",
       "       [0.41870824, 0.39563863, 0.        , 0.        ],\n",
       "       [0.38084633, 0.39563863, 0.        , 0.        ],\n",
       "       [0.        , 0.42367601, 0.        , 0.        ],\n",
       "       [0.        , 0.47975078, 0.        , 0.        ],\n",
       "       [0.        , 0.45794393, 0.        , 0.        ],\n",
       "       [0.        , 0.40186916, 0.        , 0.        ],\n",
       "       [0.        , 0.85669782, 0.        , 0.        ],\n",
       "       [0.        , 0.85046729, 0.        , 0.        ],\n",
       "       [0.        , 0.34579439, 0.        , 0.        ],\n",
       "       [0.35857461, 0.58566978, 0.07619048, 1.        ],\n",
       "       [0.07349666, 0.38006231, 0.        , 0.54901961],\n",
       "       [0.53229399, 0.39563863, 0.        , 0.        ],\n",
       "       [0.53674833, 0.28037383, 0.        , 0.        ],\n",
       "       [0.49888641, 0.41433022, 0.        , 0.        ],\n",
       "       [0.48775056, 0.42679128, 0.        , 0.        ],\n",
       "       [0.38752784, 0.3894081 , 0.        , 0.        ],\n",
       "       [0.17371938, 0.4517134 , 0.        , 0.        ],\n",
       "       [0.        , 0.56074766, 0.        , 0.        ],\n",
       "       [0.        , 0.08411215, 0.        , 0.        ],\n",
       "       [0.        , 0.01557632, 0.        , 0.        ],\n",
       "       [0.71269488, 0.47352025, 0.37777778, 0.        ],\n",
       "       [0.72605791, 0.60124611, 0.51746032, 0.        ],\n",
       "       [0.74387528, 0.29283489, 0.        , 0.        ],\n",
       "       [0.48997773, 0.55140187, 0.        , 0.        ],\n",
       "       [0.40757238, 0.31775701, 0.53333333, 0.        ],\n",
       "       [0.39643653, 0.46728972, 0.24126984, 0.        ],\n",
       "       [0.        , 0.65109034, 0.2031746 , 0.17647059],\n",
       "       [0.        , 0.7788162 , 0.12698413, 0.17647059],\n",
       "       [0.        , 0.53271028, 0.5047619 , 0.15686275],\n",
       "       [0.        , 0.52647975, 0.4984127 , 0.1372549 ],\n",
       "       [0.        , 0.74454829, 0.19365079, 0.09803922],\n",
       "       [0.        , 0.70093458, 0.25714286, 0.01960784],\n",
       "       [0.        , 0.63862928, 0.20952381, 0.        ],\n",
       "       [0.        , 0.73831776, 0.2031746 , 0.        ],\n",
       "       [0.        , 0.69158879, 0.16825397, 0.        ],\n",
       "       [0.        , 0.6105919 , 0.2       , 0.        ],\n",
       "       [0.        , 0.28037383, 0.        , 0.        ],\n",
       "       [0.        , 0.6635514 , 0.17777778, 0.        ],\n",
       "       [0.        , 0.52959502, 0.54285714, 0.        ],\n",
       "       [0.        , 0.61682243, 0.21269841, 0.        ],\n",
       "       [0.        , 0.47040498, 0.49206349, 0.        ],\n",
       "       [0.        , 0.49221184, 0.43809524, 0.        ],\n",
       "       [0.        , 0.47663551, 0.91428571, 0.        ],\n",
       "       [0.        , 0.76323988, 0.17142857, 0.        ],\n",
       "       [0.        , 0.80685358, 0.33650794, 0.        ],\n",
       "       [0.        , 0.52959502, 0.5047619 , 0.        ],\n",
       "       [0.        , 0.53894081, 0.52063492, 0.        ],\n",
       "       [0.        , 0.51401869, 0.4984127 , 0.        ],\n",
       "       [0.        , 0.5576324 , 0.53015873, 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con librería\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.02)\n",
    "sel.fit_transform(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa este resultado? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.437594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.351786</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.308550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.801782</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>0.223048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.220808</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.790646</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.062802</td>\n",
       "      <td>0.218401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285777</td>\n",
       "      <td>0.372932</td>\n",
       "      <td>0.821826</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.259294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275241</td>\n",
       "      <td>0.381955</td>\n",
       "      <td>0.806236</td>\n",
       "      <td>0.295950</td>\n",
       "      <td>0.583929</td>\n",
       "      <td>0.088567</td>\n",
       "      <td>0.245353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211150</td>\n",
       "      <td>0.309774</td>\n",
       "      <td>0.804009</td>\n",
       "      <td>0.414330</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>0.245353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.275680</td>\n",
       "      <td>0.386466</td>\n",
       "      <td>0.801782</td>\n",
       "      <td>0.264798</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.254647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.281387</td>\n",
       "      <td>0.363910</td>\n",
       "      <td>0.804009</td>\n",
       "      <td>0.236760</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.261152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.352502</td>\n",
       "      <td>0.497744</td>\n",
       "      <td>0.797327</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.405357</td>\n",
       "      <td>0.090177</td>\n",
       "      <td>0.266729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.280948</td>\n",
       "      <td>0.341353</td>\n",
       "      <td>0.801782</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.276022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200176</td>\n",
       "      <td>0.299248</td>\n",
       "      <td>0.770601</td>\n",
       "      <td>0.395639</td>\n",
       "      <td>0.605357</td>\n",
       "      <td>0.107890</td>\n",
       "      <td>0.247212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.284460</td>\n",
       "      <td>0.311278</td>\n",
       "      <td>0.815145</td>\n",
       "      <td>0.305296</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.096618</td>\n",
       "      <td>0.290892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.208077</td>\n",
       "      <td>0.323308</td>\n",
       "      <td>0.763920</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.243494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.277875</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.792873</td>\n",
       "      <td>0.305296</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.274164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.284460</td>\n",
       "      <td>0.282707</td>\n",
       "      <td>0.799555</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.285316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.312782</td>\n",
       "      <td>0.788419</td>\n",
       "      <td>0.292835</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.093398</td>\n",
       "      <td>0.275093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.293679</td>\n",
       "      <td>0.293233</td>\n",
       "      <td>0.817372</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>0.303903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.474539</td>\n",
       "      <td>0.545865</td>\n",
       "      <td>0.857461</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.345725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.349429</td>\n",
       "      <td>0.476692</td>\n",
       "      <td>0.830735</td>\n",
       "      <td>0.277259</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.321561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.272169</td>\n",
       "      <td>0.344361</td>\n",
       "      <td>0.788419</td>\n",
       "      <td>0.436137</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.279740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Indice_Refraccion        Na        Mg        Al        Si         K  \\\n",
       "0            0.432836  0.437594  1.000000  0.252336  0.351786  0.009662   \n",
       "1            0.283582  0.475188  0.801782  0.333333  0.521429  0.077295   \n",
       "2            0.220808  0.421053  0.790646  0.389408  0.567857  0.062802   \n",
       "3            0.285777  0.372932  0.821826  0.311526  0.500000  0.091787   \n",
       "4            0.275241  0.381955  0.806236  0.295950  0.583929  0.088567   \n",
       "5            0.211150  0.309774  0.804009  0.414330  0.564286  0.103060   \n",
       "6            0.275680  0.386466  0.801782  0.264798  0.585714  0.093398   \n",
       "7            0.281387  0.363910  0.804009  0.236760  0.612500  0.091787   \n",
       "8            0.352502  0.497744  0.797327  0.336449  0.405357  0.090177   \n",
       "9            0.280948  0.341353  0.801782  0.333333  0.567857  0.091787   \n",
       "10           0.200176  0.299248  0.770601  0.395639  0.605357  0.107890   \n",
       "11           0.284460  0.311278  0.815145  0.305296  0.571429  0.096618   \n",
       "12           0.208077  0.323308  0.763920  0.345794  0.619643  0.111111   \n",
       "13           0.277875  0.320301  0.792873  0.305296  0.607143  0.086957   \n",
       "14           0.284460  0.282707  0.799555  0.317757  0.621429  0.093398   \n",
       "15           0.283582  0.312782  0.788419  0.292835  0.612500  0.093398   \n",
       "16           0.293679  0.293233  0.817372  0.271028  0.589286  0.098229   \n",
       "17           0.474539  0.545865  0.857461  0.186916  0.276786  0.024155   \n",
       "18           0.349429  0.476692  0.830735  0.277259  0.412500  0.009662   \n",
       "19           0.272169  0.344361  0.788419  0.436137  0.521429  0.086957   \n",
       "\n",
       "          Ca   Ba        Fe  \n",
       "0   0.308550  0.0  0.000000  \n",
       "1   0.223048  0.0  0.000000  \n",
       "2   0.218401  0.0  0.000000  \n",
       "3   0.259294  0.0  0.000000  \n",
       "4   0.245353  0.0  0.000000  \n",
       "5   0.245353  0.0  0.509804  \n",
       "6   0.254647  0.0  0.000000  \n",
       "7   0.261152  0.0  0.000000  \n",
       "8   0.266729  0.0  0.000000  \n",
       "9   0.276022  0.0  0.215686  \n",
       "10  0.247212  0.0  0.470588  \n",
       "11  0.290892  0.0  0.000000  \n",
       "12  0.243494  0.0  0.470588  \n",
       "13  0.274164  0.0  0.333333  \n",
       "14  0.285316  0.0  0.000000  \n",
       "15  0.275093  0.0  0.000000  \n",
       "16  0.303903  0.0  0.000000  \n",
       "17  0.345725  0.0  0.000000  \n",
       "18  0.321561  0.0  0.000000  \n",
       "19  0.279740  0.0  0.137255  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Qué pasa si tenemos datos con variables dicotómicas/binarias?*\n",
    "\n",
    "Supongamos que tenemos un dataset con variables dicotómicas y queremos remover todos los atributos que sean uno o cero en más del 80% de la muestra. \n",
    "\n",
    "$$\\begin{matrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\\\ 0& 1 & 1 \\\\ 0 & 1 & 0 \\\\  0 & 1 & 1 \\end{matrix}$$\n",
    "\n",
    "Las variables dicotómicas son variables aleatorios de Bernoulli, y la varianza está dada por:\n",
    "\n",
    "$$Var[x]=p*(1-p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método quitó la primer columna, que tiene una probabilidad de p=5/6>0.8 de contener un cero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlación entre pares (sin tomar en cuenta la variable target \"Y\")\n",
    "\n",
    "$$y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\epsilon$$\n",
    "\n",
    "Cuando existe correlación entre 2 variables predictoras \"X\", no podemos determinar el efecto de una 1 variable tomando en cuenta que la otra variable es constante ya que las dos variables cambian juntas. \n",
    "\n",
    "Cuando se tienen variables relacionadas, se puede considerar que todas las variables proporcionan la misma información al modelo. Por lo que, es deseable seleccionar solo variables que no estén relacionadas y evitar redundancia de información.\n",
    "\n",
    "Si dos variables están altamente correlacionadas, dejar sólo una va a ayudar a reducir la dimensionalidad sin perder mucha información.\n",
    "\n",
    "La matriz de correlaciones puede ayudar a visualizar si existen variables candidatas a ser descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Local\\Temp\\ipykernel_8068\\3720957934.py:6: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  co.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9a95f_row0_col0, #T_9a95f_row1_col1, #T_9a95f_row2_col2, #T_9a95f_row3_col3, #T_9a95f_row4_col4, #T_9a95f_row5_col5, #T_9a95f_row6_col6, #T_9a95f_row7_col7, #T_9a95f_row8_col8 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col1 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col2 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row0_col3 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col4, #T_9a95f_row1_col8, #T_9a95f_row2_col1, #T_9a95f_row2_col3, #T_9a95f_row2_col6, #T_9a95f_row2_col7, #T_9a95f_row4_col0, #T_9a95f_row6_col1, #T_9a95f_row6_col5, #T_9a95f_row7_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col5 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col6 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row0_col7 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row0_col8 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row1_col0, #T_9a95f_row7_col6 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row1_col2, #T_9a95f_row7_col8 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row1_col3 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row1_col4 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row1_col5 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row1_col6 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row1_col7 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row2_col0 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row2_col4, #T_9a95f_row2_col5 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row2_col8, #T_9a95f_row4_col7 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row3_col0, #T_9a95f_row5_col6 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row3_col1 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row3_col2, #T_9a95f_row5_col1 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row3_col4, #T_9a95f_row7_col0 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row3_col5 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row3_col6 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row3_col7, #T_9a95f_row7_col3 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row3_col8 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row4_col1, #T_9a95f_row4_col6, #T_9a95f_row5_col0 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row4_col2, #T_9a95f_row6_col4 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row4_col3 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row4_col5 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row4_col8 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row5_col2 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row5_col3 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row5_col4 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row5_col7 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row5_col8 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row6_col0 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row6_col2 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row6_col3 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row6_col7 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row6_col8 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row7_col1 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row7_col4 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row7_col5 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row8_col0 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row8_col1 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9a95f_row8_col2 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row8_col3 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row8_col4, #T_9a95f_row8_col7 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row8_col5 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9a95f_row8_col6 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9a95f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Indice_Refraccion</th>\n",
       "      <th class=\"col_heading level0 col1\" >Na</th>\n",
       "      <th class=\"col_heading level0 col2\" >Mg</th>\n",
       "      <th class=\"col_heading level0 col3\" >Al</th>\n",
       "      <th class=\"col_heading level0 col4\" >Si</th>\n",
       "      <th class=\"col_heading level0 col5\" >K</th>\n",
       "      <th class=\"col_heading level0 col6\" >Ca</th>\n",
       "      <th class=\"col_heading level0 col7\" >Ba</th>\n",
       "      <th class=\"col_heading level0 col8\" >Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row0\" class=\"row_heading level0 row0\" >Indice_Refraccion</th>\n",
       "      <td id=\"T_9a95f_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row0_col1\" class=\"data row0 col1\" >-0.19</td>\n",
       "      <td id=\"T_9a95f_row0_col2\" class=\"data row0 col2\" >-0.12</td>\n",
       "      <td id=\"T_9a95f_row0_col3\" class=\"data row0 col3\" >-0.41</td>\n",
       "      <td id=\"T_9a95f_row0_col4\" class=\"data row0 col4\" >-0.54</td>\n",
       "      <td id=\"T_9a95f_row0_col5\" class=\"data row0 col5\" >-0.29</td>\n",
       "      <td id=\"T_9a95f_row0_col6\" class=\"data row0 col6\" >0.81</td>\n",
       "      <td id=\"T_9a95f_row0_col7\" class=\"data row0 col7\" >-0.00</td>\n",
       "      <td id=\"T_9a95f_row0_col8\" class=\"data row0 col8\" >0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row1\" class=\"row_heading level0 row1\" >Na</th>\n",
       "      <td id=\"T_9a95f_row1_col0\" class=\"data row1 col0\" >-0.19</td>\n",
       "      <td id=\"T_9a95f_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row1_col2\" class=\"data row1 col2\" >-0.27</td>\n",
       "      <td id=\"T_9a95f_row1_col3\" class=\"data row1 col3\" >0.16</td>\n",
       "      <td id=\"T_9a95f_row1_col4\" class=\"data row1 col4\" >-0.07</td>\n",
       "      <td id=\"T_9a95f_row1_col5\" class=\"data row1 col5\" >-0.27</td>\n",
       "      <td id=\"T_9a95f_row1_col6\" class=\"data row1 col6\" >-0.28</td>\n",
       "      <td id=\"T_9a95f_row1_col7\" class=\"data row1 col7\" >0.33</td>\n",
       "      <td id=\"T_9a95f_row1_col8\" class=\"data row1 col8\" >-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row2\" class=\"row_heading level0 row2\" >Mg</th>\n",
       "      <td id=\"T_9a95f_row2_col0\" class=\"data row2 col0\" >-0.12</td>\n",
       "      <td id=\"T_9a95f_row2_col1\" class=\"data row2 col1\" >-0.27</td>\n",
       "      <td id=\"T_9a95f_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row2_col3\" class=\"data row2 col3\" >-0.48</td>\n",
       "      <td id=\"T_9a95f_row2_col4\" class=\"data row2 col4\" >-0.17</td>\n",
       "      <td id=\"T_9a95f_row2_col5\" class=\"data row2 col5\" >0.01</td>\n",
       "      <td id=\"T_9a95f_row2_col6\" class=\"data row2 col6\" >-0.44</td>\n",
       "      <td id=\"T_9a95f_row2_col7\" class=\"data row2 col7\" >-0.49</td>\n",
       "      <td id=\"T_9a95f_row2_col8\" class=\"data row2 col8\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row3\" class=\"row_heading level0 row3\" >Al</th>\n",
       "      <td id=\"T_9a95f_row3_col0\" class=\"data row3 col0\" >-0.41</td>\n",
       "      <td id=\"T_9a95f_row3_col1\" class=\"data row3 col1\" >0.16</td>\n",
       "      <td id=\"T_9a95f_row3_col2\" class=\"data row3 col2\" >-0.48</td>\n",
       "      <td id=\"T_9a95f_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row3_col4\" class=\"data row3 col4\" >-0.01</td>\n",
       "      <td id=\"T_9a95f_row3_col5\" class=\"data row3 col5\" >0.33</td>\n",
       "      <td id=\"T_9a95f_row3_col6\" class=\"data row3 col6\" >-0.26</td>\n",
       "      <td id=\"T_9a95f_row3_col7\" class=\"data row3 col7\" >0.48</td>\n",
       "      <td id=\"T_9a95f_row3_col8\" class=\"data row3 col8\" >-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row4\" class=\"row_heading level0 row4\" >Si</th>\n",
       "      <td id=\"T_9a95f_row4_col0\" class=\"data row4 col0\" >-0.54</td>\n",
       "      <td id=\"T_9a95f_row4_col1\" class=\"data row4 col1\" >-0.07</td>\n",
       "      <td id=\"T_9a95f_row4_col2\" class=\"data row4 col2\" >-0.17</td>\n",
       "      <td id=\"T_9a95f_row4_col3\" class=\"data row4 col3\" >-0.01</td>\n",
       "      <td id=\"T_9a95f_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row4_col5\" class=\"data row4 col5\" >-0.19</td>\n",
       "      <td id=\"T_9a95f_row4_col6\" class=\"data row4 col6\" >-0.21</td>\n",
       "      <td id=\"T_9a95f_row4_col7\" class=\"data row4 col7\" >-0.10</td>\n",
       "      <td id=\"T_9a95f_row4_col8\" class=\"data row4 col8\" >-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row5\" class=\"row_heading level0 row5\" >K</th>\n",
       "      <td id=\"T_9a95f_row5_col0\" class=\"data row5 col0\" >-0.29</td>\n",
       "      <td id=\"T_9a95f_row5_col1\" class=\"data row5 col1\" >-0.27</td>\n",
       "      <td id=\"T_9a95f_row5_col2\" class=\"data row5 col2\" >0.01</td>\n",
       "      <td id=\"T_9a95f_row5_col3\" class=\"data row5 col3\" >0.33</td>\n",
       "      <td id=\"T_9a95f_row5_col4\" class=\"data row5 col4\" >-0.19</td>\n",
       "      <td id=\"T_9a95f_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row5_col6\" class=\"data row5 col6\" >-0.32</td>\n",
       "      <td id=\"T_9a95f_row5_col7\" class=\"data row5 col7\" >-0.04</td>\n",
       "      <td id=\"T_9a95f_row5_col8\" class=\"data row5 col8\" >-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row6\" class=\"row_heading level0 row6\" >Ca</th>\n",
       "      <td id=\"T_9a95f_row6_col0\" class=\"data row6 col0\" >0.81</td>\n",
       "      <td id=\"T_9a95f_row6_col1\" class=\"data row6 col1\" >-0.28</td>\n",
       "      <td id=\"T_9a95f_row6_col2\" class=\"data row6 col2\" >-0.44</td>\n",
       "      <td id=\"T_9a95f_row6_col3\" class=\"data row6 col3\" >-0.26</td>\n",
       "      <td id=\"T_9a95f_row6_col4\" class=\"data row6 col4\" >-0.21</td>\n",
       "      <td id=\"T_9a95f_row6_col5\" class=\"data row6 col5\" >-0.32</td>\n",
       "      <td id=\"T_9a95f_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row6_col7\" class=\"data row6 col7\" >-0.11</td>\n",
       "      <td id=\"T_9a95f_row6_col8\" class=\"data row6 col8\" >0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row7\" class=\"row_heading level0 row7\" >Ba</th>\n",
       "      <td id=\"T_9a95f_row7_col0\" class=\"data row7 col0\" >-0.00</td>\n",
       "      <td id=\"T_9a95f_row7_col1\" class=\"data row7 col1\" >0.33</td>\n",
       "      <td id=\"T_9a95f_row7_col2\" class=\"data row7 col2\" >-0.49</td>\n",
       "      <td id=\"T_9a95f_row7_col3\" class=\"data row7 col3\" >0.48</td>\n",
       "      <td id=\"T_9a95f_row7_col4\" class=\"data row7 col4\" >-0.10</td>\n",
       "      <td id=\"T_9a95f_row7_col5\" class=\"data row7 col5\" >-0.04</td>\n",
       "      <td id=\"T_9a95f_row7_col6\" class=\"data row7 col6\" >-0.11</td>\n",
       "      <td id=\"T_9a95f_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_9a95f_row7_col8\" class=\"data row7 col8\" >-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a95f_level0_row8\" class=\"row_heading level0 row8\" >Fe</th>\n",
       "      <td id=\"T_9a95f_row8_col0\" class=\"data row8 col0\" >0.14</td>\n",
       "      <td id=\"T_9a95f_row8_col1\" class=\"data row8 col1\" >-0.24</td>\n",
       "      <td id=\"T_9a95f_row8_col2\" class=\"data row8 col2\" >0.08</td>\n",
       "      <td id=\"T_9a95f_row8_col3\" class=\"data row8 col3\" >-0.07</td>\n",
       "      <td id=\"T_9a95f_row8_col4\" class=\"data row8 col4\" >-0.09</td>\n",
       "      <td id=\"T_9a95f_row8_col5\" class=\"data row8 col5\" >-0.01</td>\n",
       "      <td id=\"T_9a95f_row8_col6\" class=\"data row8 col6\" >0.12</td>\n",
       "      <td id=\"T_9a95f_row8_col7\" class=\"data row8 col7\" >-0.06</td>\n",
       "      <td id=\"T_9a95f_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x140aa8dcf10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separar X de Y\n",
    "X = data.iloc[:,1:10]\n",
    "Y = data.iloc[:,10]\n",
    "\n",
    "co= X.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y ahora?\n",
    "\n",
    "1. Determinar la matriz de correlaciones de las variables\n",
    "2. Determinar el par de variables con correlación más alta. (𝑋𝑎 y 𝑋𝑏)\n",
    "3. Determinar el promedio de la correlación de 𝑋𝑎 contra todas las demás variables, y hacer lo mismo para 𝑋𝑏.\n",
    "4. Se remueve la variable con mayor correlación promedio.\n",
    "5. Repetir los pasos 2-4 hasta que las correlaciones de mantengan por debajo de un umbral deseado (𝜌𝑋𝑎𝑋𝑏<0.75).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.075\n",
      "-0.08124999999999999\n"
     ]
    }
   ],
   "source": [
    "corr_prom_Xa= (-.19-.12-.41-.54-.29+.81+.14)/8  #Indice Refraccion\n",
    "corr_prom_Xb = (.81-.28-.4-.26-.21-.32-.11+.12)/8  #Calcio\n",
    "print(corr_prom_Xa) #Indice Refraccion\n",
    "print(corr_prom_Xb) #Calcio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto quitamos el índice de refracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Na    Mg    Al     Si     K    Ca    Ba   Fe\n",
       "0    13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
       "1    13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
       "2    13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
       "3    13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
       "4    13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
       "..     ...   ...   ...    ...   ...   ...   ...  ...\n",
       "209  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
       "210  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
       "211  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
       "212  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
       "213  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
       "\n",
       "[214 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevasX=X.iloc[:,1:9]\n",
    "nuevasX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Local\\Temp\\ipykernel_8068\\3878305145.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  co.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8a387_row0_col0, #T_8a387_row1_col1, #T_8a387_row2_col2, #T_8a387_row3_col3, #T_8a387_row4_col4, #T_8a387_row5_col5, #T_8a387_row6_col6, #T_8a387_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row0_col1, #T_8a387_row6_col7 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row0_col2 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row0_col3, #T_8a387_row0_col5 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row0_col4 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row0_col6 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row0_col7, #T_8a387_row1_col0, #T_8a387_row1_col2, #T_8a387_row1_col5, #T_8a387_row1_col6, #T_8a387_row5_col0, #T_8a387_row5_col3, #T_8a387_row5_col4, #T_8a387_row6_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row1_col3 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row1_col4 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row1_col7, #T_8a387_row3_col6 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row2_col0 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row2_col1, #T_8a387_row4_col0 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row2_col3 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row2_col4 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row2_col5 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row2_col6, #T_8a387_row6_col2 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row2_col7 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row3_col0, #T_8a387_row3_col5 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row3_col1 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row3_col2 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row3_col4, #T_8a387_row7_col3 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row3_col7 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row4_col1 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row4_col2 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row4_col3 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row4_col5, #T_8a387_row6_col3 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row4_col6 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row4_col7 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row5_col1 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row5_col2 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row5_col6 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row5_col7 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row6_col0 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row6_col4 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row6_col5 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row7_col0 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8a387_row7_col1 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row7_col2 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row7_col4 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row7_col5 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8a387_row7_col6 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8a387_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Na</th>\n",
       "      <th class=\"col_heading level0 col1\" >Mg</th>\n",
       "      <th class=\"col_heading level0 col2\" >Al</th>\n",
       "      <th class=\"col_heading level0 col3\" >Si</th>\n",
       "      <th class=\"col_heading level0 col4\" >K</th>\n",
       "      <th class=\"col_heading level0 col5\" >Ca</th>\n",
       "      <th class=\"col_heading level0 col6\" >Ba</th>\n",
       "      <th class=\"col_heading level0 col7\" >Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row0\" class=\"row_heading level0 row0\" >Na</th>\n",
       "      <td id=\"T_8a387_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_8a387_row0_col1\" class=\"data row0 col1\" >-0.27</td>\n",
       "      <td id=\"T_8a387_row0_col2\" class=\"data row0 col2\" >0.16</td>\n",
       "      <td id=\"T_8a387_row0_col3\" class=\"data row0 col3\" >-0.07</td>\n",
       "      <td id=\"T_8a387_row0_col4\" class=\"data row0 col4\" >-0.27</td>\n",
       "      <td id=\"T_8a387_row0_col5\" class=\"data row0 col5\" >-0.28</td>\n",
       "      <td id=\"T_8a387_row0_col6\" class=\"data row0 col6\" >0.33</td>\n",
       "      <td id=\"T_8a387_row0_col7\" class=\"data row0 col7\" >-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row1\" class=\"row_heading level0 row1\" >Mg</th>\n",
       "      <td id=\"T_8a387_row1_col0\" class=\"data row1 col0\" >-0.27</td>\n",
       "      <td id=\"T_8a387_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_8a387_row1_col2\" class=\"data row1 col2\" >-0.48</td>\n",
       "      <td id=\"T_8a387_row1_col3\" class=\"data row1 col3\" >-0.17</td>\n",
       "      <td id=\"T_8a387_row1_col4\" class=\"data row1 col4\" >0.01</td>\n",
       "      <td id=\"T_8a387_row1_col5\" class=\"data row1 col5\" >-0.44</td>\n",
       "      <td id=\"T_8a387_row1_col6\" class=\"data row1 col6\" >-0.49</td>\n",
       "      <td id=\"T_8a387_row1_col7\" class=\"data row1 col7\" >0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row2\" class=\"row_heading level0 row2\" >Al</th>\n",
       "      <td id=\"T_8a387_row2_col0\" class=\"data row2 col0\" >0.16</td>\n",
       "      <td id=\"T_8a387_row2_col1\" class=\"data row2 col1\" >-0.48</td>\n",
       "      <td id=\"T_8a387_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_8a387_row2_col3\" class=\"data row2 col3\" >-0.01</td>\n",
       "      <td id=\"T_8a387_row2_col4\" class=\"data row2 col4\" >0.33</td>\n",
       "      <td id=\"T_8a387_row2_col5\" class=\"data row2 col5\" >-0.26</td>\n",
       "      <td id=\"T_8a387_row2_col6\" class=\"data row2 col6\" >0.48</td>\n",
       "      <td id=\"T_8a387_row2_col7\" class=\"data row2 col7\" >-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row3\" class=\"row_heading level0 row3\" >Si</th>\n",
       "      <td id=\"T_8a387_row3_col0\" class=\"data row3 col0\" >-0.07</td>\n",
       "      <td id=\"T_8a387_row3_col1\" class=\"data row3 col1\" >-0.17</td>\n",
       "      <td id=\"T_8a387_row3_col2\" class=\"data row3 col2\" >-0.01</td>\n",
       "      <td id=\"T_8a387_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_8a387_row3_col4\" class=\"data row3 col4\" >-0.19</td>\n",
       "      <td id=\"T_8a387_row3_col5\" class=\"data row3 col5\" >-0.21</td>\n",
       "      <td id=\"T_8a387_row3_col6\" class=\"data row3 col6\" >-0.10</td>\n",
       "      <td id=\"T_8a387_row3_col7\" class=\"data row3 col7\" >-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row4\" class=\"row_heading level0 row4\" >K</th>\n",
       "      <td id=\"T_8a387_row4_col0\" class=\"data row4 col0\" >-0.27</td>\n",
       "      <td id=\"T_8a387_row4_col1\" class=\"data row4 col1\" >0.01</td>\n",
       "      <td id=\"T_8a387_row4_col2\" class=\"data row4 col2\" >0.33</td>\n",
       "      <td id=\"T_8a387_row4_col3\" class=\"data row4 col3\" >-0.19</td>\n",
       "      <td id=\"T_8a387_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_8a387_row4_col5\" class=\"data row4 col5\" >-0.32</td>\n",
       "      <td id=\"T_8a387_row4_col6\" class=\"data row4 col6\" >-0.04</td>\n",
       "      <td id=\"T_8a387_row4_col7\" class=\"data row4 col7\" >-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row5\" class=\"row_heading level0 row5\" >Ca</th>\n",
       "      <td id=\"T_8a387_row5_col0\" class=\"data row5 col0\" >-0.28</td>\n",
       "      <td id=\"T_8a387_row5_col1\" class=\"data row5 col1\" >-0.44</td>\n",
       "      <td id=\"T_8a387_row5_col2\" class=\"data row5 col2\" >-0.26</td>\n",
       "      <td id=\"T_8a387_row5_col3\" class=\"data row5 col3\" >-0.21</td>\n",
       "      <td id=\"T_8a387_row5_col4\" class=\"data row5 col4\" >-0.32</td>\n",
       "      <td id=\"T_8a387_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_8a387_row5_col6\" class=\"data row5 col6\" >-0.11</td>\n",
       "      <td id=\"T_8a387_row5_col7\" class=\"data row5 col7\" >0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row6\" class=\"row_heading level0 row6\" >Ba</th>\n",
       "      <td id=\"T_8a387_row6_col0\" class=\"data row6 col0\" >0.33</td>\n",
       "      <td id=\"T_8a387_row6_col1\" class=\"data row6 col1\" >-0.49</td>\n",
       "      <td id=\"T_8a387_row6_col2\" class=\"data row6 col2\" >0.48</td>\n",
       "      <td id=\"T_8a387_row6_col3\" class=\"data row6 col3\" >-0.10</td>\n",
       "      <td id=\"T_8a387_row6_col4\" class=\"data row6 col4\" >-0.04</td>\n",
       "      <td id=\"T_8a387_row6_col5\" class=\"data row6 col5\" >-0.11</td>\n",
       "      <td id=\"T_8a387_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_8a387_row6_col7\" class=\"data row6 col7\" >-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a387_level0_row7\" class=\"row_heading level0 row7\" >Fe</th>\n",
       "      <td id=\"T_8a387_row7_col0\" class=\"data row7 col0\" >-0.24</td>\n",
       "      <td id=\"T_8a387_row7_col1\" class=\"data row7 col1\" >0.08</td>\n",
       "      <td id=\"T_8a387_row7_col2\" class=\"data row7 col2\" >-0.07</td>\n",
       "      <td id=\"T_8a387_row7_col3\" class=\"data row7 col3\" >-0.09</td>\n",
       "      <td id=\"T_8a387_row7_col4\" class=\"data row7 col4\" >-0.01</td>\n",
       "      <td id=\"T_8a387_row7_col5\" class=\"data row7 col5\" >0.12</td>\n",
       "      <td id=\"T_8a387_row7_col6\" class=\"data row7 col6\" >-0.06</td>\n",
       "      <td id=\"T_8a387_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x140b094d120>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co= nuevasX.corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos sólo la variable \"Índice de Refracción\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de eliminación tomando en cuenta X y Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de la correlación contra la variable target \"Y\"\n",
    "\n",
    "- Eliminar variables que tienen una correlación baja con la variable a predecir\n",
    "\n",
    "- Si una variable tiene baja correlación con el target, no va a ser útil para la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael\\AppData\\Local\\Temp\\ipykernel_8068\\1855992814.py:2: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  co.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_558e1_row0_col0, #T_558e1_row1_col1, #T_558e1_row2_col2, #T_558e1_row3_col3, #T_558e1_row4_col4, #T_558e1_row5_col5, #T_558e1_row6_col6, #T_558e1_row7_col7, #T_558e1_row8_col8, #T_558e1_row9_col9 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col1 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col2 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row0_col3 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col4, #T_558e1_row1_col8, #T_558e1_row2_col1, #T_558e1_row2_col3, #T_558e1_row2_col6, #T_558e1_row2_col7, #T_558e1_row2_col9, #T_558e1_row4_col0, #T_558e1_row6_col1, #T_558e1_row6_col5, #T_558e1_row9_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col5 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col6 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row0_col7, #T_558e1_row4_col2 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row0_col8 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row0_col9 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row1_col0, #T_558e1_row7_col6 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row1_col2, #T_558e1_row2_col0 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row1_col3, #T_558e1_row5_col2 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row1_col4, #T_558e1_row9_col6 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row1_col5, #T_558e1_row9_col8 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row1_col6 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row1_col7 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row1_col9, #T_558e1_row9_col7 {\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row2_col4, #T_558e1_row2_col5, #T_558e1_row9_col0 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row2_col8, #T_558e1_row4_col7 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row3_col0, #T_558e1_row5_col6 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row3_col1 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row3_col2, #T_558e1_row6_col3 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row3_col4, #T_558e1_row7_col0 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row3_col5 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row3_col6 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row3_col7, #T_558e1_row7_col3 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row3_col8 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row3_col9 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row4_col1, #T_558e1_row4_col6, #T_558e1_row5_col0 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row4_col3 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row4_col5 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row4_col8 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row4_col9 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row5_col1 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row5_col3 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row5_col4 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row5_col7 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row5_col8 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row5_col9 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row6_col0 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row6_col2 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row6_col4 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row6_col7 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row6_col8 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row6_col9 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row7_col1 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row7_col2, #T_558e1_row7_col8 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row7_col4 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row7_col5 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row7_col9 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col0 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col1 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_558e1_row8_col2 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col3 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col4, #T_558e1_row8_col7 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col5 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col6 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row8_col9 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row9_col1 {\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row9_col3 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row9_col4 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_558e1_row9_col5 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_558e1_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Indice_Refraccion</th>\n",
       "      <th class=\"col_heading level0 col1\" >Na</th>\n",
       "      <th class=\"col_heading level0 col2\" >Mg</th>\n",
       "      <th class=\"col_heading level0 col3\" >Al</th>\n",
       "      <th class=\"col_heading level0 col4\" >Si</th>\n",
       "      <th class=\"col_heading level0 col5\" >K</th>\n",
       "      <th class=\"col_heading level0 col6\" >Ca</th>\n",
       "      <th class=\"col_heading level0 col7\" >Ba</th>\n",
       "      <th class=\"col_heading level0 col8\" >Fe</th>\n",
       "      <th class=\"col_heading level0 col9\" >Tipo_Vidrio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row0\" class=\"row_heading level0 row0\" >Indice_Refraccion</th>\n",
       "      <td id=\"T_558e1_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_558e1_row0_col1\" class=\"data row0 col1\" >-0.19</td>\n",
       "      <td id=\"T_558e1_row0_col2\" class=\"data row0 col2\" >-0.12</td>\n",
       "      <td id=\"T_558e1_row0_col3\" class=\"data row0 col3\" >-0.41</td>\n",
       "      <td id=\"T_558e1_row0_col4\" class=\"data row0 col4\" >-0.54</td>\n",
       "      <td id=\"T_558e1_row0_col5\" class=\"data row0 col5\" >-0.29</td>\n",
       "      <td id=\"T_558e1_row0_col6\" class=\"data row0 col6\" >0.81</td>\n",
       "      <td id=\"T_558e1_row0_col7\" class=\"data row0 col7\" >-0.00</td>\n",
       "      <td id=\"T_558e1_row0_col8\" class=\"data row0 col8\" >0.14</td>\n",
       "      <td id=\"T_558e1_row0_col9\" class=\"data row0 col9\" >-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row1\" class=\"row_heading level0 row1\" >Na</th>\n",
       "      <td id=\"T_558e1_row1_col0\" class=\"data row1 col0\" >-0.19</td>\n",
       "      <td id=\"T_558e1_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_558e1_row1_col2\" class=\"data row1 col2\" >-0.27</td>\n",
       "      <td id=\"T_558e1_row1_col3\" class=\"data row1 col3\" >0.16</td>\n",
       "      <td id=\"T_558e1_row1_col4\" class=\"data row1 col4\" >-0.07</td>\n",
       "      <td id=\"T_558e1_row1_col5\" class=\"data row1 col5\" >-0.27</td>\n",
       "      <td id=\"T_558e1_row1_col6\" class=\"data row1 col6\" >-0.28</td>\n",
       "      <td id=\"T_558e1_row1_col7\" class=\"data row1 col7\" >0.33</td>\n",
       "      <td id=\"T_558e1_row1_col8\" class=\"data row1 col8\" >-0.24</td>\n",
       "      <td id=\"T_558e1_row1_col9\" class=\"data row1 col9\" >0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row2\" class=\"row_heading level0 row2\" >Mg</th>\n",
       "      <td id=\"T_558e1_row2_col0\" class=\"data row2 col0\" >-0.12</td>\n",
       "      <td id=\"T_558e1_row2_col1\" class=\"data row2 col1\" >-0.27</td>\n",
       "      <td id=\"T_558e1_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_558e1_row2_col3\" class=\"data row2 col3\" >-0.48</td>\n",
       "      <td id=\"T_558e1_row2_col4\" class=\"data row2 col4\" >-0.17</td>\n",
       "      <td id=\"T_558e1_row2_col5\" class=\"data row2 col5\" >0.01</td>\n",
       "      <td id=\"T_558e1_row2_col6\" class=\"data row2 col6\" >-0.44</td>\n",
       "      <td id=\"T_558e1_row2_col7\" class=\"data row2 col7\" >-0.49</td>\n",
       "      <td id=\"T_558e1_row2_col8\" class=\"data row2 col8\" >0.08</td>\n",
       "      <td id=\"T_558e1_row2_col9\" class=\"data row2 col9\" >-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row3\" class=\"row_heading level0 row3\" >Al</th>\n",
       "      <td id=\"T_558e1_row3_col0\" class=\"data row3 col0\" >-0.41</td>\n",
       "      <td id=\"T_558e1_row3_col1\" class=\"data row3 col1\" >0.16</td>\n",
       "      <td id=\"T_558e1_row3_col2\" class=\"data row3 col2\" >-0.48</td>\n",
       "      <td id=\"T_558e1_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_558e1_row3_col4\" class=\"data row3 col4\" >-0.01</td>\n",
       "      <td id=\"T_558e1_row3_col5\" class=\"data row3 col5\" >0.33</td>\n",
       "      <td id=\"T_558e1_row3_col6\" class=\"data row3 col6\" >-0.26</td>\n",
       "      <td id=\"T_558e1_row3_col7\" class=\"data row3 col7\" >0.48</td>\n",
       "      <td id=\"T_558e1_row3_col8\" class=\"data row3 col8\" >-0.07</td>\n",
       "      <td id=\"T_558e1_row3_col9\" class=\"data row3 col9\" >0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row4\" class=\"row_heading level0 row4\" >Si</th>\n",
       "      <td id=\"T_558e1_row4_col0\" class=\"data row4 col0\" >-0.54</td>\n",
       "      <td id=\"T_558e1_row4_col1\" class=\"data row4 col1\" >-0.07</td>\n",
       "      <td id=\"T_558e1_row4_col2\" class=\"data row4 col2\" >-0.17</td>\n",
       "      <td id=\"T_558e1_row4_col3\" class=\"data row4 col3\" >-0.01</td>\n",
       "      <td id=\"T_558e1_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_558e1_row4_col5\" class=\"data row4 col5\" >-0.19</td>\n",
       "      <td id=\"T_558e1_row4_col6\" class=\"data row4 col6\" >-0.21</td>\n",
       "      <td id=\"T_558e1_row4_col7\" class=\"data row4 col7\" >-0.10</td>\n",
       "      <td id=\"T_558e1_row4_col8\" class=\"data row4 col8\" >-0.09</td>\n",
       "      <td id=\"T_558e1_row4_col9\" class=\"data row4 col9\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row5\" class=\"row_heading level0 row5\" >K</th>\n",
       "      <td id=\"T_558e1_row5_col0\" class=\"data row5 col0\" >-0.29</td>\n",
       "      <td id=\"T_558e1_row5_col1\" class=\"data row5 col1\" >-0.27</td>\n",
       "      <td id=\"T_558e1_row5_col2\" class=\"data row5 col2\" >0.01</td>\n",
       "      <td id=\"T_558e1_row5_col3\" class=\"data row5 col3\" >0.33</td>\n",
       "      <td id=\"T_558e1_row5_col4\" class=\"data row5 col4\" >-0.19</td>\n",
       "      <td id=\"T_558e1_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_558e1_row5_col6\" class=\"data row5 col6\" >-0.32</td>\n",
       "      <td id=\"T_558e1_row5_col7\" class=\"data row5 col7\" >-0.04</td>\n",
       "      <td id=\"T_558e1_row5_col8\" class=\"data row5 col8\" >-0.01</td>\n",
       "      <td id=\"T_558e1_row5_col9\" class=\"data row5 col9\" >-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row6\" class=\"row_heading level0 row6\" >Ca</th>\n",
       "      <td id=\"T_558e1_row6_col0\" class=\"data row6 col0\" >0.81</td>\n",
       "      <td id=\"T_558e1_row6_col1\" class=\"data row6 col1\" >-0.28</td>\n",
       "      <td id=\"T_558e1_row6_col2\" class=\"data row6 col2\" >-0.44</td>\n",
       "      <td id=\"T_558e1_row6_col3\" class=\"data row6 col3\" >-0.26</td>\n",
       "      <td id=\"T_558e1_row6_col4\" class=\"data row6 col4\" >-0.21</td>\n",
       "      <td id=\"T_558e1_row6_col5\" class=\"data row6 col5\" >-0.32</td>\n",
       "      <td id=\"T_558e1_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_558e1_row6_col7\" class=\"data row6 col7\" >-0.11</td>\n",
       "      <td id=\"T_558e1_row6_col8\" class=\"data row6 col8\" >0.12</td>\n",
       "      <td id=\"T_558e1_row6_col9\" class=\"data row6 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row7\" class=\"row_heading level0 row7\" >Ba</th>\n",
       "      <td id=\"T_558e1_row7_col0\" class=\"data row7 col0\" >-0.00</td>\n",
       "      <td id=\"T_558e1_row7_col1\" class=\"data row7 col1\" >0.33</td>\n",
       "      <td id=\"T_558e1_row7_col2\" class=\"data row7 col2\" >-0.49</td>\n",
       "      <td id=\"T_558e1_row7_col3\" class=\"data row7 col3\" >0.48</td>\n",
       "      <td id=\"T_558e1_row7_col4\" class=\"data row7 col4\" >-0.10</td>\n",
       "      <td id=\"T_558e1_row7_col5\" class=\"data row7 col5\" >-0.04</td>\n",
       "      <td id=\"T_558e1_row7_col6\" class=\"data row7 col6\" >-0.11</td>\n",
       "      <td id=\"T_558e1_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_558e1_row7_col8\" class=\"data row7 col8\" >-0.06</td>\n",
       "      <td id=\"T_558e1_row7_col9\" class=\"data row7 col9\" >0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row8\" class=\"row_heading level0 row8\" >Fe</th>\n",
       "      <td id=\"T_558e1_row8_col0\" class=\"data row8 col0\" >0.14</td>\n",
       "      <td id=\"T_558e1_row8_col1\" class=\"data row8 col1\" >-0.24</td>\n",
       "      <td id=\"T_558e1_row8_col2\" class=\"data row8 col2\" >0.08</td>\n",
       "      <td id=\"T_558e1_row8_col3\" class=\"data row8 col3\" >-0.07</td>\n",
       "      <td id=\"T_558e1_row8_col4\" class=\"data row8 col4\" >-0.09</td>\n",
       "      <td id=\"T_558e1_row8_col5\" class=\"data row8 col5\" >-0.01</td>\n",
       "      <td id=\"T_558e1_row8_col6\" class=\"data row8 col6\" >0.12</td>\n",
       "      <td id=\"T_558e1_row8_col7\" class=\"data row8 col7\" >-0.06</td>\n",
       "      <td id=\"T_558e1_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_558e1_row8_col9\" class=\"data row8 col9\" >-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_558e1_level0_row9\" class=\"row_heading level0 row9\" >Tipo_Vidrio</th>\n",
       "      <td id=\"T_558e1_row9_col0\" class=\"data row9 col0\" >-0.16</td>\n",
       "      <td id=\"T_558e1_row9_col1\" class=\"data row9 col1\" >0.50</td>\n",
       "      <td id=\"T_558e1_row9_col2\" class=\"data row9 col2\" >-0.74</td>\n",
       "      <td id=\"T_558e1_row9_col3\" class=\"data row9 col3\" >0.60</td>\n",
       "      <td id=\"T_558e1_row9_col4\" class=\"data row9 col4\" >0.15</td>\n",
       "      <td id=\"T_558e1_row9_col5\" class=\"data row9 col5\" >-0.01</td>\n",
       "      <td id=\"T_558e1_row9_col6\" class=\"data row9 col6\" >0.00</td>\n",
       "      <td id=\"T_558e1_row9_col7\" class=\"data row9 col7\" >0.58</td>\n",
       "      <td id=\"T_558e1_row9_col8\" class=\"data row9 col8\" >-0.19</td>\n",
       "      <td id=\"T_558e1_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x140b01d1810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co= data.iloc[:,1:11].corr()\n",
    "co.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso yo podría quitar la variable de \"Ca\" ya que no tiene correlación con la variable a predecir \"Tipo de Vidrio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de Envoltura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación Recursiva de Características (RFE)\n",
    "\n",
    "Funciona eliminando atributos de forma recursiva y construyendo un modelo sobre los atributos que quedan.\n",
    "\n",
    "Usa la precisión del modelo para identificar qué atributos (y combinación de atributos) contribuyen más a predecir el objetivo.\n",
    "\n",
    "Vamos a utilizar la regresión logística para seleccionar las 4 características principales. La elección del algoritmo no importa demasiado siempre que sea hábil y consistente con el tipo de problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Logistic Regression (aka logit, MaxEnt) classifier.\n",
      "\n",
      "In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      "scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      "cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      "(Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      "'sag', 'saga' and 'newton-cg' solvers.)\n",
      "\n",
      "This class implements regularized logistic regression using the\n",
      "'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      "that regularization is applied by default**. It can handle both dense\n",
      "and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      "floats for optimal performance; any other input format will be converted\n",
      "(and copied).\n",
      "\n",
      "The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      "with primal formulation, or no regularization. The 'liblinear' solver\n",
      "supports both L1 and L2 regularization, with a dual formulation only for\n",
      "the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      "'saga' solver.\n",
      "\n",
      "Read more in the :ref:`User Guide <logistic_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
      "    Specify the norm of the penalty:\n",
      "\n",
      "    - `'none'`: no penalty is added;\n",
      "    - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      "    - `'l1'`: add a L1 penalty term;\n",
      "    - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      "\n",
      "    .. warning::\n",
      "       Some penalties may not work with some solvers. See the parameter\n",
      "       `solver` below, to know the compatibility between the penalty and\n",
      "       solver.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "       l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      "\n",
      "dual : bool, default=False\n",
      "    Dual or primal formulation. Dual formulation is only implemented for\n",
      "    l2 penalty with liblinear solver. Prefer dual=False when\n",
      "    n_samples > n_features.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    Tolerance for stopping criteria.\n",
      "\n",
      "C : float, default=1.0\n",
      "    Inverse of regularization strength; must be a positive float.\n",
      "    Like in support vector machines, smaller values specify stronger\n",
      "    regularization.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "    added to the decision function.\n",
      "\n",
      "intercept_scaling : float, default=1\n",
      "    Useful only when the solver 'liblinear' is used\n",
      "    and self.fit_intercept is set to True. In this case, x becomes\n",
      "    [x, self.intercept_scaling],\n",
      "    i.e. a \"synthetic\" feature with constant value equal to\n",
      "    intercept_scaling is appended to the instance vector.\n",
      "    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      "\n",
      "    Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "    as all other features.\n",
      "    To lessen the effect of regularization on synthetic feature weight\n",
      "    (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "\n",
      "class_weight : dict or 'balanced', default=None\n",
      "    Weights associated with classes in the form ``{class_label: weight}``.\n",
      "    If not given, all classes are supposed to have weight one.\n",
      "\n",
      "    The \"balanced\" mode uses the values of y to automatically adjust\n",
      "    weights inversely proportional to class frequencies in the input data\n",
      "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "\n",
      "    Note that these weights will be multiplied with sample_weight (passed\n",
      "    through the fit method) if sample_weight is specified.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       *class_weight='balanced'*\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      "    data. See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
      "\n",
      "    Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      "    To choose a solver, you might want to consider the following aspects:\n",
      "\n",
      "        - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      "          and 'saga' are faster for large ones;\n",
      "        - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      "          'lbfgs' handle multinomial loss;\n",
      "        - 'liblinear' is limited to one-versus-rest schemes.\n",
      "\n",
      "    .. warning::\n",
      "       The choice of the algorithm depends on the penalty chosen:\n",
      "       Supported penalties by solver:\n",
      "\n",
      "       - 'newton-cg'   -   ['l2', 'none']\n",
      "       - 'lbfgs'       -   ['l2', 'none']\n",
      "       - 'liblinear'   -   ['l1', 'l2']\n",
      "       - 'sag'         -   ['l2', 'none']\n",
      "       - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
      "\n",
      "    .. note::\n",
      "       'sag' and 'saga' fast convergence is only guaranteed on\n",
      "       features with approximately the same scale. You can\n",
      "       preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
      "\n",
      "    .. seealso::\n",
      "       Refer to the User Guide for more information regarding\n",
      "       :class:`LogisticRegression` and more specifically the\n",
      "       :ref:`Table <Logistic_regression>`\n",
      "       summarizing solver/penalty supports.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       Stochastic Average Gradient descent solver.\n",
      "    .. versionadded:: 0.19\n",
      "       SAGA solver.\n",
      "    .. versionchanged:: 0.22\n",
      "        The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      "\n",
      "max_iter : int, default=100\n",
      "    Maximum number of iterations taken for the solvers to converge.\n",
      "\n",
      "multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
      "    label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      "    across the entire probability distribution, *even when the data is\n",
      "    binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      "    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      "    and otherwise selects 'multinomial'.\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "       Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      "    .. versionchanged:: 0.22\n",
      "        Default changed from 'ovr' to 'auto' in 0.22.\n",
      "\n",
      "verbose : int, default=0\n",
      "    For the liblinear and lbfgs solvers set verbose to any positive\n",
      "    number for verbosity.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to True, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of CPU cores used when parallelizing over classes if\n",
      "    multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      "    set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      "    not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "    context. ``-1`` means using all processors.\n",
      "    See :term:`Glossary <n_jobs>` for more details.\n",
      "\n",
      "l1_ratio : float, default=None\n",
      "    The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      "    used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      "    to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      "    to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "\n",
      "classes_ : ndarray of shape (n_classes, )\n",
      "    A list of class labels known to the classifier.\n",
      "\n",
      "coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "    Coefficient of the features in the decision function.\n",
      "\n",
      "    `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      "    In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      "    to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      "\n",
      "intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      "    Intercept (a.k.a. bias) added to the decision function.\n",
      "\n",
      "    If `fit_intercept` is set to False, the intercept is set to zero.\n",
      "    `intercept_` is of shape (1,) when the given problem is binary.\n",
      "    In particular, when `multi_class='multinomial'`, `intercept_`\n",
      "    corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      "    outcome 0 (False).\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      "    Actual number of iterations for all classes. If binary or multinomial,\n",
      "    it returns only 1 element. For liblinear solver, only the maximum\n",
      "    number of iteration across all classes is given.\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "\n",
      "        In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      "        ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "SGDClassifier : Incrementally trained logistic regression (when given\n",
      "    the parameter ``loss=\"log\"``).\n",
      "LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The underlying C implementation uses a random number generator to\n",
      "select features when fitting the model. It is thus not uncommon,\n",
      "to have slightly different results for the same input data. If\n",
      "that happens, try with a smaller tol parameter.\n",
      "\n",
      "Predict output may not match that of standalone liblinear in certain\n",
      "cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      "in the narrative documentation.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      "    Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      "    http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      "\n",
      "LIBLINEAR -- A Library for Large Linear Classification\n",
      "    https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      "\n",
      "SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      "    Minimizing Finite Sums with the Stochastic Average Gradient\n",
      "    https://hal.inria.fr/hal-00860051/document\n",
      "\n",
      "SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      "        :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
      "        for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
      "\n",
      "Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      "    methods for logistic regression and maximum entropy models.\n",
      "    Machine Learning 85(1-2):41-75.\n",
      "    https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import load_iris\n",
      ">>> from sklearn.linear_model import LogisticRegression\n",
      ">>> X, y = load_iris(return_X_y=True)\n",
      ">>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      ">>> clf.predict(X[:2, :])\n",
      "array([0, 0])\n",
      ">>> clf.predict_proba(X[:2, :])\n",
      "array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      "       [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      ">>> clf.score(X, y)\n",
      "0.97...\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     LogisticRegressionCV\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de características: 4\n",
      "Características seleccionadas: [False False  True  True False  True False  True False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#crear modelo de regresión logística\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "#crear el recursive feature elimination para la regresión logística, seleccionando sólo 4 variables\n",
    "rfe = RFE(model, n_features_to_select= 4)\n",
    "#ajusta modelo\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"# de características: %d\" % fit.n_features_)\n",
    "print(\"Características seleccionadas: %s\" % fit.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Tipo_Vidrio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Indice_Refraccion     Na    Mg    Al     Si     K    Ca   Ba   Fe  \\\n",
       "0   1            1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   \n",
       "1   2            1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   \n",
       "2   3            1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   \n",
       "3   4            1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   \n",
       "4   5            1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   \n",
       "\n",
       "   Tipo_Vidrio  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>K</th>\n",
       "      <th>Ba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mg    Al     K    Ba\n",
       "0    4.49  1.10  0.06  0.00\n",
       "1    3.60  1.36  0.48  0.00\n",
       "2    3.55  1.54  0.39  0.00\n",
       "3    3.69  1.29  0.57  0.00\n",
       "4    3.62  1.24  0.55  0.00\n",
       "..    ...   ...   ...   ...\n",
       "209  0.00  2.88  0.08  1.06\n",
       "210  0.00  1.99  0.00  1.59\n",
       "211  0.00  2.02  0.00  1.64\n",
       "212  0.00  1.94  0.00  1.57\n",
       "213  0.00  2.08  0.00  1.67\n",
       "\n",
       "[214 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[:, fit.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RFE eligió las siguientes variables: Mg, Al, K, Ba \n",
    "Están marcadas como \"True\". \n",
    "De igual manera, los resultados pueden variar dependiendo de la naturaleza estocástica del algoritmo o el proceso de evaluación, o diferencias en la precisión numérica. Se recomienda correr el ejercicio varias veces para comparar el resultado promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos embebidos (intrínsecos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables basada en árboles\n",
    "\n",
    "Modelos basados en árboles como el \"Random Forest\" y los \"Extra Trees\" ya tienen dentro de su proceso un método de seleción de variables donde estiman la importancia de los atributos. \n",
    "\n",
    "Construimos un Clasificador de \"Extra Tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mg</td>\n",
       "      <td>0.166803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ca</td>\n",
       "      <td>0.156450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al</td>\n",
       "      <td>0.156440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indice_Refraccion</td>\n",
       "      <td>0.117318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K</td>\n",
       "      <td>0.109316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.099744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na</td>\n",
       "      <td>0.081647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ba</td>\n",
       "      <td>0.062808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fe</td>\n",
       "      <td>0.049472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Attribute  Importance\n",
       "2                 Mg    0.166803\n",
       "6                 Ca    0.156450\n",
       "3                 Al    0.156440\n",
       "0  Indice_Refraccion    0.117318\n",
       "5                  K    0.109316\n",
       "4                 Si    0.099744\n",
       "1                 Na    0.081647\n",
       "7                 Ba    0.062808\n",
       "8                 Fe    0.049472"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance con clasificador de Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# crear objeto de Extra Trees\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "#Ajustar modelo a datos\n",
    "model.fit(X, Y)\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute':data.iloc[:,1:10].columns, \n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 4 variables más importantes serían: Mg, Al, Ca e Indice de Refraccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Importancia de los atributos obtenido de los coeficientes', size=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Least Absolute Shrinkage and Selection Operator (LASSO)\n",
    "\n",
    "Lo que hace LASSO es que tiene un parámetro de regularización que penaliza a algunas variables y las hace cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar en datos de entrenamiento y de prueba\n",
    "X= data.drop(labels=['ID', 'Tipo_Vidrio'], axis=1)\n",
    "Y= data['Tipo_Vidrio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Tipo_Vidrio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Indice_Refraccion     Na    Mg    Al     Si     K    Ca   Ba   Fe  \\\n",
       "0   1            1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0   \n",
       "1   2            1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0   \n",
       "2   3            1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0   \n",
       "3   4            1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0   \n",
       "4   5            1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0   \n",
       "\n",
       "   Tipo_Vidrio  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de los modelos lineales se benefician de escalar los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escalar datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Rafael\\anaconda3\\envs\\lpd\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LASSO\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel=LogisticRegression(C=1, penalty='l1', solver='liblinear').fit(X,Y) #LASSO  = L1\n",
    "sel=SelectFromModel(sel, prefit=True)\n",
    "X_new=sel.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2      3     4     5     6    7\n",
       "0    13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
       "1    13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
       "2    13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
       "3    13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
       "4    13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
       "..     ...   ...   ...    ...   ...   ...   ...  ...\n",
       "209  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
       "210  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
       "211  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
       "212  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
       "213  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
       "\n",
       "[214 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice_Refraccion</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indice_Refraccion     Na    Mg    Al     Si     K    Ca   Ba   Fe\n",
       "0            1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0\n",
       "1            1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0\n",
       "2            1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0\n",
       "3            1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0\n",
       "4            1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo quitó la variable \"Indice de Refracción\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el mejor método?\n",
    "\n",
    "...no hay...\n",
    "\n",
    "Se tiene que hacer experimentación para ver qué método funciona mejor para el problema en específico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "- Comparison of F-test and mutual information: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py\n",
    "- Feature selection: https://scikit-learn.org/stable/modules/feature_selection.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Sara E. Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f252e278f79bddb4614af97a2b0077329c579290cfaee85b3430e069b1aba70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
